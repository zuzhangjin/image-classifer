{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4acfbfa683d41b88117b6babd0a0e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff6a04bf95e846bfb9813df27361f30e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32d6f32a0db84ac681965b7923f1bd5c",
              "IPY_MODEL_99460521c1f24b20ab4d891ba779d643"
            ]
          }
        },
        "ff6a04bf95e846bfb9813df27361f30e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32d6f32a0db84ac681965b7923f1bd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1741e2a4d1034cc4a803b91dba254bfd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108949747,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108949747,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f409fa5d55e543179a7b96e9eaf06e9e"
          }
        },
        "99460521c1f24b20ab4d891ba779d643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_997036b4d2b44a6cb1673d401b32a5fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 79.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11881e519fa94570888fef621fc2d224"
          }
        },
        "1741e2a4d1034cc4a803b91dba254bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f409fa5d55e543179a7b96e9eaf06e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "997036b4d2b44a6cb1673d401b32a5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11881e519fa94570888fef621fc2d224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmW_TT6tCoVI",
        "outputId": "e196e8e3-c97f-46ac-e22c-d48ec291ff0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsh_iBl7CjH0"
      },
      "source": [
        "# copy dataset from google drive to colab\n",
        "!cp ./drive/My\\ Drive/stanford_car_dataset.zip ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYe-Sl_GCl97",
        "outputId": "c3d9c8bd-6572-455f-bf0a-68c1f730d180"
      },
      "source": [
        "%%time\n",
        "# unzip dataset in colab\n",
        "!mkdir ./stanford_car_dataset\n",
        "!unzip -q stanford_car_dataset.zip -d ./stanford_car_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 231 ms, sys: 44.3 ms, total: 275 ms\n",
            "Wall time: 49.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNXb_BitTUFi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import os\n",
        "import tqdm\n",
        "import PIL.Image as Image\n",
        "from IPython.display import display\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9bkNYOjCvvz"
      },
      "source": [
        "dataset_dir = \"stanford_car_dataset/car_data/car_data/\"\n",
        "\n",
        "# data transformation, you can try different transformation/ data augmentation here\n",
        "# note: no data augmentation for test data\n",
        "\n",
        "# width, height = 224, 224 # models except to inception_V3\n",
        "width, height = 299, 299  # for inception_v3\n",
        "train_tfms = transforms.Compose([transforms.Resize((width, height)),\n",
        "                                 # transforms.RandomHorizontalFlip(),\n",
        "                                 # transforms.RandomRotation(15),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_tfms = transforms.Compose([transforms.Resize((width, height)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "# create datasets\n",
        "dataset = torchvision.datasets.ImageFolder(root=dataset_dir + \"train\", transform=train_tfms)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\n",
        "testloader = torch.utils.data.DataLoader(dataset2, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DAAw__1CyBb"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, n_epochs=5):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # set the model to train mode initially\n",
        "    model.train()\n",
        "    for epoch in tqdm.tqdm(range(n_epochs)):\n",
        "        since = time.time()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "            # get the inputs and assign them to cuda\n",
        "            inputs, labels = data\n",
        "            #inputs = inputs.to(device).half() # uncomment for half precision model\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            # print(outputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # calculate the loss/acc later\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (labels==predicted).sum().item()\n",
        "\n",
        "        epoch_duration = time.time() - since\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_acc = 100 / 32 * running_correct / len(trainloader)\n",
        "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
        "        \n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "        \n",
        "        # switch the model to eval mode to evaluate on test data\n",
        "        model.eval()\n",
        "        test_acc = eval_model(model)\n",
        "        test_accuracies.append(test_acc)\n",
        "        \n",
        "        # re-set the model to train mode after validating\n",
        "        model.train()\n",
        "        scheduler.step(test_acc)\n",
        "        since = time.time()\n",
        "    print('Finished Training')\n",
        "    return model, losses, accuracies, test_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND47TrIkC0_k"
      },
      "source": [
        "def eval_model(model):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "            images, labels = data\n",
        "            #images = images.to(device).half() # uncomment for half precision model\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model_ft(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100.0 * correct / total\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        test_acc))\n",
        "    return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Dd5zQGC3Eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "f4acfbfa683d41b88117b6babd0a0e9b",
            "ff6a04bf95e846bfb9813df27361f30e",
            "32d6f32a0db84ac681965b7923f1bd5c",
            "99460521c1f24b20ab4d891ba779d643",
            "1741e2a4d1034cc4a803b91dba254bfd",
            "f409fa5d55e543179a7b96e9eaf06e9e",
            "997036b4d2b44a6cb1673d401b32a5fd",
            "11881e519fa94570888fef621fc2d224"
          ]
        },
        "outputId": "ab87ded0-1939-49fe-dc39-9b572d397b2b"
      },
      "source": [
        "NUM_CAR_CLASSES = 196\n",
        "model_ft = models.inception_v3(pretrained=True)\n",
        "model_ft.aux_logits = False\n",
        "\n",
        "# Freezing model parameters and defining the fully connected network to be attached to the model, \n",
        "# loss function and the optimizer.\n",
        "# We there after put the model on the GPUs\n",
        "# for param in model_ft.parameters():\n",
        "#     param.require_grad = False\n",
        "\n",
        "# replace the last fc layer with an untrained one (requires grad by default)\n",
        "\n",
        "# for inception_V3\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, NUM_CAR_CLASSES)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# uncomment this block for half precision model\n",
        "\"\"\"\n",
        "model_ft = model_ft.half()\n",
        "for layer in model_ft.modules():\n",
        "    if isinstance(layer, nn.BatchNorm2d):\n",
        "        layer.float()\n",
        "\"\"\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "\"\"\"\n",
        "probably not the best metric to track, but we are tracking the training accuracy and measuring whether\n",
        "it increases by atleast 0.9 per epoch and if it hasn't increased by 0.9 reduce the lr by 0.1x.\n",
        "However in this model it did not benefit me.\n",
        "\"\"\"\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4acfbfa683d41b88117b6babd0a0e9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108949747.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQE88oqiC5RM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42ee163-9039-4d71-c3d8-cbb009707d6f"
      },
      "source": [
        "# use inception_v3\n",
        "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, duration: 118 s, loss: 4.0262, acc: 12.6471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|â–Œ         | 1/20 [03:25<1:05:09, 205.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 34 %\n",
            "Epoch 2, duration: 119 s, loss: 1.7556, acc: 51.9240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|â–ˆ         | 2/20 [06:53<1:01:52, 206.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 61 %\n",
            "Epoch 3, duration: 119 s, loss: 0.8683, acc: 75.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|â–ˆâ–Œ        | 3/20 [10:20<58:30, 206.53s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 70 %\n",
            "Epoch 4, duration: 119 s, loss: 0.4664, acc: 86.7279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 4/20 [13:48<55:11, 206.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 76 %\n",
            "Epoch 5, duration: 119 s, loss: 0.2588, acc: 92.7328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|â–ˆâ–ˆâ–Œ       | 5/20 [17:15<51:43, 206.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 80 %\n",
            "Epoch 6, duration: 119 s, loss: 0.1462, acc: 96.1275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [20:42<48:19, 207.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 82 %\n",
            "Epoch 7, duration: 119 s, loss: 0.0953, acc: 97.6471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [24:09<44:49, 206.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 83 %\n",
            "Epoch 8, duration: 120 s, loss: 0.0468, acc: 98.9828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [27:35<41:20, 206.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 9, duration: 119 s, loss: 0.0295, acc: 99.4363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [31:01<37:52, 206.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 10, duration: 120 s, loss: 0.0246, acc: 99.4975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [34:28<34:26, 206.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 11, duration: 119 s, loss: 0.0218, acc: 99.5466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [37:54<30:58, 206.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 88 %\n",
            "Epoch 12, duration: 119 s, loss: 0.0192, acc: 99.5956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [41:20<27:30, 206.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 13, duration: 119 s, loss: 0.0197, acc: 99.5221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [44:47<24:04, 206.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 14, duration: 119 s, loss: 0.0208, acc: 99.5588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [48:13<20:38, 206.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 88 %\n",
            "Epoch 15, duration: 119 s, loss: 0.0183, acc: 99.6201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [51:39<17:10, 206.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 16, duration: 119 s, loss: 0.0185, acc: 99.5466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [55:07<13:47, 206.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 17, duration: 119 s, loss: 0.0191, acc: 99.6201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [58:33<10:19, 206.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 18, duration: 119 s, loss: 0.0187, acc: 99.6569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [1:01:58<06:52, 206.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Epoch 19, duration: 119 s, loss: 0.0180, acc: 99.6569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [1:05:23<03:25, 205.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 88 %\n",
            "Epoch 20, duration: 119 s, loss: 0.0186, acc: 99.5588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [1:08:49<00:00, 206.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 87 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5EfZOVtC8n8"
      },
      "source": [
        "# plot the stats\n",
        "\n",
        "f, axarr = plt.subplots(2,2, figsize = (12, 8))\n",
        "axarr[0, 0].plot(training_losses)\n",
        "axarr[0, 0].set_title(\"Training loss\")\n",
        "axarr[0, 1].plot(training_accs)\n",
        "axarr[0, 1].set_title(\"Training acc\")\n",
        "axarr[1, 0].plot(test_accs)\n",
        "\n",
        "axarr[1, 0].set_title(\"Test acc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIyVIuHDAIT"
      },
      "source": [
        "# tie the class indices to their names\n",
        "\n",
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "classes, c_to_idx = find_classes(dataset_dir+\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkuHB9SEDEMV"
      },
      "source": [
        "# test the model on random images\n",
        "\n",
        "# switch the model to evaluation mode to make dropout and batch norm work in eval mode\n",
        "model_ft.eval()\n",
        "\n",
        "# transforms for the input image\n",
        "loader = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "image = Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\")\n",
        "image = loader(image).float()\n",
        "image = torch.autograd.Variable(image, requires_grad=True)\n",
        "image = image.unsqueeze(0)\n",
        "image = image.cuda()\n",
        "output = model_ft(image)\n",
        "conf, predicted = torch.max(output.data, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLqJhhlRDGYd"
      },
      "source": [
        "# get the class name of the prediction\n",
        "display(Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\"))\n",
        "print(classes[predicted.item()], \"confidence: \", conf.item())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}